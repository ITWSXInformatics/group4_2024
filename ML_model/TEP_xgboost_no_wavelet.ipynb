{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import cv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d83ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''mean-std noralization'''\n",
    "def normalization_1(data):\n",
    "    \n",
    "    data_mean = np.mean(data,0)   #(72,)\n",
    "    data_std = np.std(data,0,ddof=1) \n",
    "    data_ = (data - data_mean)/data_std\n",
    "    \n",
    "    return data_, data_mean , data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''max-min noralization'''\n",
    "def normalization_2(data):\n",
    "    \n",
    "    data_min = np.min(data, 0)\n",
    "    data_max = np.max(data, 0) \n",
    "    data_ = (data - data_min) / (data_max - data_min + 1e-7)\n",
    "    \n",
    "    return data_, data_min , data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''one-hot label'''\n",
    "def to_categorical(y, num_classes=None):\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''one-hot label'''\n",
    "# first arg: label\n",
    "# second arg: num of class \n",
    "def one_hot ( labels , Label_class ): \n",
    "    one_hot_label = np.array([[ int (i == int (labels[j])) for i in range (Label_class)] for j in range ( len (labels))])      \n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13023dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''doing wavelet on input data, and spilt them by slidding window'''\n",
    "def add_window(x, time_step):\n",
    "    \n",
    "    x_window = []\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        series = x[i]\n",
    "        series_window = []\n",
    "        for j in range(int(series.shape[0]//time_step)):\n",
    "            dat = series[j: j+time_step]\n",
    "            series_window.append(dat.reshape([-1]))\n",
    "        x_window.append(series_window)\n",
    "    \n",
    "    return np.array(x_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbfcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''spilt labe by slidding window in order to be align with input data'''\n",
    "\n",
    "def label_add_window(x, time_step):\n",
    "    \n",
    "    x_window = []\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        series = x[i]\n",
    "        series_window = []\n",
    "        for j in range(int(series.shape[0]//time_step)):\n",
    "            dat = series[j: j+time_step]\n",
    "            series_window.append(dat[0])\n",
    "        x_window.append(series_window)\n",
    "    \n",
    "    return np.array(x_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c2e53",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b82093",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = \"tep_train\"\n",
    "filenames = []\n",
    "train_feature = []\n",
    "train_lable = []\n",
    "\n",
    "for filename in os.listdir(filedir):\n",
    "    filenames.append(os.path.join(filedir,filename))\n",
    "\n",
    "# print(filenames)\n",
    "    \n",
    "filenames = [\n",
    "'tep_train\\\\d01.dat', 'tep_train\\\\d02.dat', 'tep_train\\\\d03.dat',\n",
    "'tep_train\\\\d04.dat', 'tep_train\\\\d05.dat', 'tep_train\\\\d06.dat',\n",
    "'tep_train\\\\d07.dat', 'tep_train\\\\d08.dat',\n",
    "'tep_train\\\\d10.dat', 'tep_train\\\\d11.dat', 'tep_train\\\\d12.dat', \n",
    "'tep_train\\\\d13.dat', 'tep_train\\\\d14.dat', 'tep_train\\\\d15.dat',\n",
    "'tep_train\\\\d16.dat', 'tep_train\\\\d17.dat', 'tep_train\\\\d18.dat',\n",
    "'tep_train\\\\d19.dat', 'tep_train\\\\d20.dat', 'tep_train\\\\d21.dat'\n",
    "]\n",
    "print(\"num of class, aka the amount of abnormality: \",len(filenames))\n",
    "\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    tep = np.genfromtxt(filenames[i])\n",
    "    train_feature.append(tep)\n",
    "    \n",
    "    label = np.ones(tep.shape[0])*i\n",
    "    train_lable.append(label)\n",
    "    \n",
    "train_feature = np.array(train_feature)\n",
    "train_lable = np.array(train_lable)\n",
    "\n",
    "print(train_feature.shape)\n",
    "print(train_lable.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef9cbb",
   "metadata": {},
   "source": [
    "# Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = \"tep_test\"\n",
    "filenames_test = []\n",
    "\n",
    "test_normal = []\n",
    "test_fault = []\n",
    "val = []\n",
    "\n",
    "test_normal_label = []\n",
    "test_fault_label = []\n",
    "val_label = []\n",
    "\n",
    "for filename in os.listdir(filedir):\n",
    "    filenames_test.append(os.path.join(filedir,filename))\n",
    "    \n",
    "# print(filenames_test)\n",
    "\n",
    "filenames_test = [\n",
    "'tep_test\\\\d01_te.dat', 'tep_test\\\\d02_te.dat', 'tep_test\\\\d03_te.dat',\n",
    "'tep_test\\\\d04_te.dat', 'tep_test\\\\d05_te.dat', 'tep_test\\\\d06_te.dat',\n",
    "'tep_test\\\\d07_te.dat', 'tep_test\\\\d08_te.dat',\n",
    "'tep_test\\\\d10_te.dat', 'tep_test\\\\d11_te.dat', 'tep_test\\\\d12_te.dat', \n",
    "'tep_test\\\\d13_te.dat', 'tep_test\\\\d14_te.dat', 'tep_test\\\\d15_te.dat', \n",
    "'tep_test\\\\d16_te.dat', 'tep_test\\\\d17_te.dat', 'tep_test\\\\d18_te.dat', \n",
    "'tep_test\\\\d19_te.dat', 'tep_test\\\\d20_te.dat', 'tep_test\\\\d21_te.dat'\n",
    "]\n",
    "    \n",
    "print(\"num of class, aka the amount of abnormality: \",len(filenames_test))\n",
    "\n",
    "\n",
    "for i in range(len(filenames_test)):\n",
    "    \n",
    "    tep = np.genfromtxt(filenames_test[i])\n",
    "    test_normal_ = tep[:160]\n",
    "    test_normal.append(test_normal_)\n",
    "\n",
    "    val_ = tep[160:160+300]\n",
    "    val.append(val_)\n",
    "    \n",
    "    test_fault_ = tep[160+300:]\n",
    "    test_fault.append(test_fault_)\n",
    "\n",
    "    label = np.ones(tep.shape[0])*i\n",
    "    test_normal_label.append(label[:160])\n",
    "    test_fault_label.append(label[160+300:])\n",
    "    val_label.append(label[160:160+300])\n",
    "    \n",
    "test_normal = np.array(test_normal)\n",
    "test_fault = np.array(test_fault)\n",
    "val = np.array(val)\n",
    "test_normal_label = np.array(test_normal_label)\n",
    "test_fault_label = np.array(test_fault_label)\n",
    "val_label = np.array(val_label)\n",
    "\n",
    "print(test_normal.shape)\n",
    "print(test_fault.shape)\n",
    "print(val.shape)\n",
    "print(test_normal_label.shape)\n",
    "print(test_fault_label.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8db66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "\n",
    "train_x = add_window(train_feature, time_step).reshape([-1, time_step*tep.shape[-1]])\n",
    "train_x, data_mean , data_std = normalization_1(train_x)\n",
    "# train_x, data_min , data_max = normalization_2(train_x)\n",
    "train_y = label_add_window(train_lable, time_step).reshape([-1])\n",
    "\n",
    "val_x = add_window(val, time_step).reshape([-1, time_step*tep.shape[-1]])\n",
    "val_x = (val_x - data_mean)/data_std\n",
    "# val_x = (val_x - data_min) / (data_max - data_min + 1e-7)\n",
    "val_y = label_add_window(val_label, time_step).reshape([-1])\n",
    "\n",
    "test_normal_x = add_window(test_normal, time_step).reshape([-1, time_step*tep.shape[-1]])\n",
    "test_normal_x = (test_normal_x - data_mean)/data_std\n",
    "# test_normal_x = (test_normal_x - data_min) / (data_max - data_min + 1e-7)\n",
    "test_normal_y = label_add_window(test_normal_label, time_step).reshape([-1])\n",
    "\n",
    "test_fault_x = add_window(test_fault, time_step).reshape([-1, time_step*tep.shape[-1]])\n",
    "test_fault_x = (test_fault_x - data_mean)/data_std\n",
    "# test_fault_x = (test_fault_x - data_min) / (data_max - data_min + 1e-7)\n",
    "test_fault_y = label_add_window(test_fault_label, time_step).reshape([-1])\n",
    "\n",
    "\n",
    "print('train_x: ',train_x.shape)\n",
    "print('train_y: ',train_y.shape)\n",
    "print('----------------------------------------------')\n",
    "print('val_x: ',val_x.shape)\n",
    "print('val_y: ',val_y.shape)\n",
    "print('----------------------------------------------')\n",
    "print('test_normal_x: ',test_normal_x.shape)\n",
    "print('test_normal_y: ',test_normal_y.shape)\n",
    "print('----------------------------------------------')\n",
    "print('test_fault_x: ',test_fault_x.shape)\n",
    "print('test_fault_y: ',test_fault_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x, train_y)\n",
    "dval = xgb.DMatrix(val_x, val_y)\n",
    "dtest_normal = xgb.DMatrix(test_normal_x, test_normal_y)\n",
    "dtest_fault = xgb.DMatrix(test_fault_x, test_fault_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f9ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "'objective': 'multi:softprob',\n",
    "'num_class': len(filenames),\n",
    "'seed': 0,\n",
    "'gamma': 0,\n",
    "'max_depth': 10, #20\n",
    "# 'random_state': 0,\n",
    "'subsample': 0.3,\n",
    "'min_child_weight': 0.5,\n",
    "'lambda': 3.5,\n",
    "'grow_policy': 'lossguide',\n",
    "'eta': 0.007,\n",
    "'eval_metric': ['merror'],\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, \n",
    "          num_boost_round = 2000, \n",
    "          verbose_eval = 20, \n",
    "          early_stopping_rounds = 200, \n",
    "          evals=[(dtrain, 'train') , (dval, 'valid'), (dtest_normal, 'test_normal'), (dtest_fault, 'test_fault')],\n",
    "          )\n",
    "\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932fa167",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(xgb.DMatrix(val_x))\n",
    "yprob = np.argmax(y_pred, axis=1)  # return the index of the biggest pro\n",
    "\n",
    "predictions = [round(value) for value in yprob]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(val_y, predictions)\n",
    "print(\"Accuracy: %.5f%%\" % (accuracy * 100.0))\n",
    "print('Recall: %.4f' % metrics.recall_score(val_y, predictions, average='macro'))\n",
    "print('F1-score: %.4f' % metrics.f1_score(val_y, predictions, average='macro'))\n",
    "print('Precesion: %.4f' % metrics.precision_score(val_y, predictions, average='macro'))\n",
    "print(\"confusion_matrix:\")\n",
    "print(confusion_matrix(val_y, predictions))\n",
    "# print(\"%2.5f\" %(confusion_matrix(val_y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_matrix(val_y, predictions))\n",
    "df.to_csv('./TEP_xgboost_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xgb.DMatrix(test_fault_x))\n",
    "yprob = np.argmax(y_pred, axis=1)  # return the index of the biggest pro\n",
    "\n",
    "predictions = [round(value) for value in yprob]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(test_fault_y, predictions)\n",
    "print(\"Accuracy: %.5f%%\" % (accuracy * 100.0))\n",
    "print('Recall: %.4f' % metrics.recall_score(test_fault_y, predictions, average='macro'))\n",
    "print('F1-score: %.4f' % metrics.f1_score(test_fault_y, predictions, average='macro'))\n",
    "print('Precesion: %.4f' % metrics.precision_score(test_fault_y, predictions, average='macro'))\n",
    "print(\"confusion_matrix:\")\n",
    "print(confusion_matrix(test_fault_y, predictions))\n",
    "df = pd.DataFrame(confusion_matrix(test_fault_y, predictions))\n",
    "df.to_csv('./TEP_xgboost_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0508618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_prediction(confMatrix):\n",
    "\n",
    "    total_sum=confMatrix.sum()\n",
    "    correct_sum=(np.diag(confMatrix)).sum()\n",
    "    prediction=round(100*float(correct_sum)/float(total_sum),2)\n",
    "    print('acc:'+str(prediction)+'%')\n",
    "    \n",
    "calculate_all_prediction(confusion_matrix(test_fault_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47613ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['1','2','3','4','5','6','7','8','10','11','12','13','14','15','16','17','18','19','20','21']\n",
    "\n",
    "\n",
    "def calculae_lable_prediction(confMatrix):\n",
    "    l=len(confMatrix)\n",
    "    for i in range(l):\n",
    "        label_total_sum = confMatrix.sum(axis=1)[i]\n",
    "        label_correct_sum=confMatrix[i][i]\n",
    "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "        print('prediction:'+classes[i]+\":\"+str(prediction)+'%')\n",
    "        \n",
    "calculae_lable_prediction(confusion_matrix(test_fault_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_label_recall(confMatrix):\n",
    "    l = len(confMatrix)\n",
    "    for i in range(l):\n",
    "        label_total_sum = confMatrix.sum(axis=0)[i]\n",
    "        label_correct_sum = confMatrix[i][i]\n",
    "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "        print('recall:'+classes[i] + \":\" + str(prediction) + '%')\n",
    "\n",
    "calculate_label_recall(confusion_matrix(test_fault_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f729b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bf047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.12",
   "language": "python",
   "name": "tf1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
